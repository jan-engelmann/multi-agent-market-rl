{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight updates:  tensor([[-0.5000, -0.5000],\n",
      "        [-0.5000, -0.5000]], grad_fn=<SubBackward0>)\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[0.0022, 0.3713]])\n",
      "tensor([[0.7138, 0.0604]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from gym.spaces import Box\n",
    "\n",
    "# Dummy model\n",
    "input1 = torch.rand((1,2))\n",
    "input2 = torch.rand((1,2))\n",
    "\n",
    "\n",
    "\n",
    "full_input = torch.cat((input1, input2), axis=0)\n",
    "\n",
    "# Operations\n",
    "# Define some weights for model1 and model2\n",
    "weight1 = torch.rand((1,2), requires_grad=True)\n",
    "weight2 = torch.rand((1,2), requires_grad=True)\n",
    "\n",
    "# Concatenate the weights in order to simultaneously perform weight updates\n",
    "weights = torch.cat((weight1, weight2), axis=0)\n",
    "\n",
    "# Keep track of the initial weight values.\n",
    "old_weights = weights.clone().detach()\n",
    "\n",
    "# Add a bias to the model.\n",
    "bias = torch.rand((2,2), requires_grad=True)\n",
    "\n",
    "# Compute some operation with input, weights and bias\n",
    "output = torch.abs(torch.mul(full_input, weights) + bias)\n",
    "\n",
    "# Compute the gradient.\n",
    "\n",
    "# Define model1 with parameters \"weight1\" and model2 with parameters \"weight2\".\n",
    "optimizers = [torch.optim.Adam(params=[weight1], lr=0.5), torch.optim.Adam(params=[weight2], lr=0.5)]\n",
    "optimizers[0].zero_grad()\n",
    "optimizers[1].zero_grad()\n",
    "\n",
    "output.backward(torch.ones_like(output))\n",
    "# Update the model weights\n",
    "optimizers[0].step()\n",
    "optimizers[1].step()\n",
    "\n",
    "# Analyze the weight update.\n",
    "weights = torch.cat((weight1, weight2), axis=0)\n",
    "print(\"Weight updates: \", weights - old_weights)\n",
    "\n",
    "print(bias.grad)\n",
    "print(weight1.grad)\n",
    "print(weight2.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0])\n",
      "torch.Size([2, 3])\n",
      "tensor([[0.1446, 0.1444, 0.0192],\n",
      "        [0.5612, 0.2353, 0.1335]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "tt = torch.rand((2,3))\n",
    "kk = torch.rand((2,5))\n",
    "needed_padding = torch.nn.functional.relu(torch.tensor(tt.shape) - torch.tensor(kk.shape), inplace=True)\n",
    "print(needed_padding)\n",
    "res = F.pad(input=tt, pad=(0,needed_padding[-1],0,0), mode='constant', value=0)\n",
    "print(res.shape)\n",
    "print(res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-72-5fe64fd87c45>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0ma\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m5\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m5\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtranspose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'cuda'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mvals\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrand\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m6\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/My Files/COSS/agent_env/lib/python3.8/site-packages/torch/cuda/__init__.py\u001B[0m in \u001B[0;36m_lazy_init\u001B[0;34m()\u001B[0m\n\u001B[1;32m    162\u001B[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001B[1;32m    163\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'_cuda_getDeviceCount'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 164\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mAssertionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Torch not compiled with CUDA enabled\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    165\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0m_cudart\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    166\u001B[0m             raise AssertionError(\n",
      "\u001B[0;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5])\n",
    "b = torch.Tensor([1,2,3,5,4,2,]).unsqueeze(0).transpose(0,1)\n",
    "\n",
    "vals = torch.rand((6, 5))\n",
    "print(vals)\n",
    "\n",
    "idx = torch.stack([torch.tensor(a) == act for act in b])\n",
    "print(idx)\n",
    "print(vals[idx])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "agent_dict = {\n",
    "'sellers': {\n",
    "1: {\n",
    "'type': 'DQNAgent',\n",
    "'reservation': 12,\n",
    "'lr': 0.002,\n",
    "'multiplicity': 2\n",
    "},\n",
    "2: {\n",
    "'type': 'DQNAgent',\n",
    "'reservation': 14,\n",
    "'lr': 0.002\n",
    "}\n",
    "},\n",
    "'buyers': {\n",
    "1: {\n",
    "'type': 'DQNAgent',\n",
    "'reservation': 12,\n",
    "'lr': 0.002,\n",
    "'multiplicity': 3\n",
    "},\n",
    "2: {\n",
    "'type': 'DQNAgent',\n",
    "'reservation': 14,\n",
    "'lr': 0.002\n",
    "}\n",
    "}\n",
    "}\n",
    "n_agent = {'sellers': 0, 'buyers': 0}\n",
    "for role in ['sellers', 'buyers']:\n",
    "    for key in agent_dict[role]:\n",
    "        n_agent[role] += agent_dict[role][key].get('multiplicity', 1)\n",
    "\n",
    "a = []\n",
    "for i in range(3):\n",
    "    a += i*[i*2 + 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([2])"
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(0,5)\n",
    "a[2].unsqueeze(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}