
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Introduction &#8212; multi-agent-market-rl 26.7.21 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/alabaster.css" />
    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="introduction">
<h1><a class="toc-backref" href="#id2">Introduction</a><a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h1>
<div class="contents topic" id="table-of-contents">
<p class="topic-title">Table of Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#introduction" id="id2">Introduction</a></p>
<ul>
<li><p><a class="reference internal" href="#what-this-is" id="id3">What This Is</a></p></li>
<li><p><a class="reference internal" href="#why-we-built-this" id="id4">Why We Built This</a></p></li>
<li><p><a class="reference internal" href="#how-this-serves-our-mission" id="id5">How This Serves Our Mission</a></p></li>
<li><p><a class="reference internal" href="#code-design-philosophy" id="id6">Code Design Philosophy</a></p></li>
<li><p><a class="reference internal" href="#long-term-support-and-support-history" id="id7">Long-Term Support and Support History</a></p></li>
</ul>
</li>
</ul>
</div>
<section id="what-this-is">
<h2><a class="toc-backref" href="#id3">What This Is</a><a class="headerlink" href="#what-this-is" title="Permalink to this headline">¶</a></h2>
<p>Welcome to Spinning Up in Deep RL! This is an educational resource produced by OpenAI that makes it easier to learn about deep reinforcement learning (deep RL).</p>
<p>For the unfamiliar: <a class="reference external" href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a> (RL) is a machine learning approach for teaching agents how to solve tasks by trial and error. Deep RL refers to the combination of RL with <a class="reference external" href="http://ufldl.stanford.edu/tutorial/">deep learning</a>.</p>
<p>This module contains a variety of helpful resources, including:</p>
<ul class="simple">
<li><p>a short <a class="reference external" href="../spinningup/rl_intro.html">introduction</a> to RL terminology, kinds of algorithms, and basic theory,</p></li>
<li><p>an <a class="reference external" href="../spinningup/spinningup.html">essay</a> about how to grow into an RL research role,</p></li>
<li><p>a <a class="reference external" href="../spinningup/keypapers.html">curated list</a> of important papers organized by topic,</p></li>
<li><p>a well-documented <a class="reference external" href="https://github.com/openai/spinningup">code repo</a> of short, standalone implementations of key algorithms,</p></li>
<li><p>and a few <a class="reference external" href="../spinningup/exercises.html">exercises</a> to serve as warm-ups.</p></li>
</ul>
</section>
<section id="why-we-built-this">
<h2><a class="toc-backref" href="#id4">Why We Built This</a><a class="headerlink" href="#why-we-built-this" title="Permalink to this headline">¶</a></h2>
<p>One of the single most common questions that we hear is</p>
<blockquote>
<div><div class="line-block">
<div class="line">If I want to contribute to AI safety, how do I get started?</div>
</div>
</div></blockquote>
<p>At OpenAI, we believe that deep learning generally—and deep reinforcement learning specifically—will play central roles in the development of powerful AI technology. To ensure that AI is safe, we have to come up with safety strategies and algorithms that are compatible with this paradigm. As a result, we encourage everyone who asks this question to study these fields.</p>
<p>However, while there are many resources to help people quickly ramp up on deep learning, deep reinforcement learning is more challenging to break into. To begin with, a student of deep RL needs to have some background in math, coding, and regular deep learning. Beyond that, they need both a high-level view of the field—an awareness of what topics are studied in it, why they matter, and what’s been done already—and careful instruction on how to connect algorithm theory to algorithm code.</p>
<p>The high-level view is hard to come by because of how new the field is. There is not yet a standard deep RL textbook, so most of the knowledge is locked up in either papers or lecture series, which can take a long time to parse and digest. And learning to implement deep RL algorithms is typically painful, because either</p>
<ul class="simple">
<li><p>the paper that publishes an algorithm omits or inadvertently obscures key design details,</p></li>
<li><p>or widely-public implementations of an algorithm are hard to read, hiding how the code lines up with the algorithm.</p></li>
</ul>
<p>While fantastic repos like <a class="reference external" href="https://github.com/rlworkgroup/garage">garage</a>, <a class="reference external" href="https://github.com/openai/baselines">Baselines</a>, and <a class="reference external" href="https://github.com/ray-project/ray/tree/master/python/ray/rllib">rllib</a> make it easier for researchers who are already in the field to make progress, they build algorithms into frameworks in ways that involve many non-obvious choices and trade-offs, which makes them hard to learn from. Consequently, the field of deep RL has a pretty high barrier to entry—for new researchers as well as practitioners and hobbyists.</p>
<p>So our package here is designed to serve as the missing middle step for people who are excited by deep RL, and would like to learn how to use it or make a contribution, but don’t have a clear sense of what to study or how to transmute algorithms into code. We’ve tried to make this as helpful a launching point as possible.</p>
<p>That said, practitioners aren’t the only people who can (or should) benefit from these materials. Solving AI safety will require people with a wide range of expertise and perspectives, and many relevant professions have no connection to engineering or computer science at all. Nonetheless, everyone involved will need to learn enough about the technology to make informed decisions, and several pieces of Spinning Up address that need.</p>
</section>
<section id="how-this-serves-our-mission">
<h2><a class="toc-backref" href="#id5">How This Serves Our Mission</a><a class="headerlink" href="#how-this-serves-our-mission" title="Permalink to this headline">¶</a></h2>
<p>OpenAI’s <a class="reference external" href="https://blog.openai.com/openai-charter/">mission</a> is to ensure the safe development of AGI and the broad distribution of benefits from AI more generally. Teaching tools like Spinning Up help us make progress on both of these objectives.</p>
<p>To begin with, we move closer to broad distribution of benefits any time we help people understand what AI is and how it works. This empowers people to think critically about the many issues we anticipate will arise as AI becomes more sophisticated and important in our lives.</p>
<p>Also, critically, <a class="reference external" href="https://jobs.lever.co/openai">we need people to help</a> us work on making sure that AGI is safe. This requires a skill set which is currently in short supply because of how new the field is. We know that many people are interested in helping us, but don’t know how—here is what you should study! If you can become an expert on this material, you can make a difference on AI safety.</p>
</section>
<section id="code-design-philosophy">
<h2><a class="toc-backref" href="#id6">Code Design Philosophy</a><a class="headerlink" href="#code-design-philosophy" title="Permalink to this headline">¶</a></h2>
<p>The algorithm implementations in the Spinning Up repo are designed to be</p>
<blockquote>
<div><ul class="simple">
<li><p>as simple as possible while still being reasonably good,</p></li>
<li><p>and highly-consistent with each other to expose fundamental similarities between algorithms.</p></li>
</ul>
</div></blockquote>
<p>They are almost completely self-contained, with virtually no common code shared between them (except for logging, saving, loading, and <a class="reference external" href="https://en.wikipedia.org/wiki/Message_Passing_Interface">MPI</a> utilities), so that an interested person can study each algorithm separately without having to dig through an endless chain of dependencies to see how something is done. The implementations are patterned so that they come as close to pseudocode as possible, to minimize the gap between theory and code.</p>
<p>Importantly, they’re all structured similarly, so if you clearly understand one, jumping into the next is painless.</p>
<p>We tried to minimize the number of tricks used in each algorithm’s implementation, and minimize the differences between otherwise-similar algorithms. To give some examples of removed tricks: we omit <a class="reference external" href="https://github.com/haarnoja/sac/blob/108a4229be6f040360fcca983113df9c4ac23a6a/sac/distributions/normal.py#L69">regularization</a> terms present in the original Soft-Actor Critic code, as well as <a class="reference external" href="https://github.com/openai/baselines/blob/28aca637d0f13f4415cc5ebb778144154cff3110/baselines/run.py#L131">observation normalization</a> from all algorithms. For an example of where we’ve removed differences between algorithms: our implementations of DDPG, TD3, and SAC all follow a convention of running gradient descent updates after fixed intervals of environment interaction. (By contrast, other public implementations of these algorithms usually take slightly different approaches from each other, making them a little bit harder to compare.)</p>
<p>All algorithms are “reasonably good” in the sense that they achieve roughly the intended performance, but don’t necessarily match the best reported results in the literature on every task. Consequently, be careful if using any of these implementations for scientific benchmarking comparisons. Details on each implementation’s specific performance level can be found on our <a class="reference external" href="../spinningup/bench.html">benchmarks</a> page.</p>
</section>
<section id="long-term-support-and-support-history">
<h2><a class="toc-backref" href="#id7">Long-Term Support and Support History</a><a class="headerlink" href="#long-term-support-and-support-history" title="Permalink to this headline">¶</a></h2>
<p>Spinning Up is currently in maintenance mode. If there are any breaking bugs, we’ll repair them to ensure that Spinning Up can continue to help people study deep RL.</p>
<p>Support history so far:</p>
<ul>
<li><p><strong>Nov 8, 2018:</strong> Initial release!</p></li>
<li><p><strong>Nov, 2018:</strong> Release was followed by a three-week period of high-bandwidth support.</p></li>
<li><p><strong>April, 2019:</strong> Approximately six months after release, we conducted an internal review of Spinning Up based on feedback from the community. The review surfaced interest in a few key features:</p>
<blockquote>
<div><ul class="simple">
<li><p><strong>Implementations in Other Neural Network Libraries.</strong> Several people expressed interest in seeing Spinning Up use alternatives to Tensorflow v1 for the RL implementations. A few members of the community even developed their own PyTorch versions of Spinning Up algorithms, such as Kashif Rasul’s <a class="reference external" href="https://github.com/kashif/firedup">Fired Up</a>,  Kai Arulkumaran’s <a class="reference external" href="https://github.com/Kaixhin/spinning-up-basic">Spinning Up Basic</a>, and Misha Laskin’s <a class="reference external" href="https://github.com/MishaLaskin/torchingup">Torching Up</a>. As a result, making this kind of “Rosetta Stone” for deep RL became a high priority for future work.</p></li>
<li><p><strong>Open Source RL Environments.</strong> Many people expressed an interest in seeing Spinning Up use more open source RL environments (eg <a class="reference external" href="https://pybullet.org/wordpress/">PyBullet</a>) for benchmarks, examples, and exercises.</p></li>
<li><p><strong>More Algorithms.</strong> There was some interest in seeing other algorithms included in Spinning Up, especially Deep Q-Networks.</p></li>
</ul>
</div></blockquote>
</li>
<li><p><strong>Jan, 2020:</strong> The PyTorch update to Spinning Up was released!</p></li>
<li><p><strong>Future:</strong> No major updates are currently planned for Spinning Up. In the event it makes sense for us to release an additional update, following what we found in the 6-month review, the next-highest priority features are to focus more on open source RL environments and adding algorithms.</p></li>
</ul>
<p>Additionally, as discussed in the blog post, Spinning Up has been integrated into the curriculum for our <a class="reference external" href="https://openai.com/blog/openai-scholars-spring-2020/">Scholars</a> and <a class="reference external" href="https://openai.com/blog/openai-fellows-fall-2018/">Fellows</a> programs.</p>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../index.html">multi-agent-market-rl</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../MultiAgentMarketRL.html">Multi-Agent-Market-RL</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2021, Benjamin Suter.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.1.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../../../../_sources/submodules/spinningup-rl-tutorial/docs/user/introduction.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>