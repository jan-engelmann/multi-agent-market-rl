
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Experiment Outputs &#8212; multi-agent-market-rl 26.7.21 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/alabaster.css" />
    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="experiment-outputs">
<h1><a class="toc-backref" href="#id1">Experiment Outputs</a><a class="headerlink" href="#experiment-outputs" title="Permalink to this headline">¶</a></h1>
<div class="contents topic" id="table-of-contents">
<p class="topic-title">Table of Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#experiment-outputs" id="id1">Experiment Outputs</a></p>
<ul>
<li><p><a class="reference internal" href="#algorithm-outputs" id="id2">Algorithm Outputs</a></p>
<ul>
<li><p><a class="reference internal" href="#pytorch-save-directory-info" id="id3">PyTorch Save Directory Info</a></p></li>
<li><p><a class="reference internal" href="#tensorflow-save-directory-info" id="id4">Tensorflow Save Directory Info</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#save-directory-location" id="id5">Save Directory Location</a></p></li>
<li><p><a class="reference internal" href="#loading-and-running-trained-policies" id="id6">Loading and Running Trained Policies</a></p>
<ul>
<li><p><a class="reference internal" href="#if-environment-saves-successfully" id="id7">If Environment Saves Successfully</a></p></li>
<li><p><a class="reference internal" href="#environment-not-found-error" id="id8">Environment Not Found Error</a></p></li>
<li><p><a class="reference internal" href="#using-trained-value-functions" id="id9">Using Trained Value Functions</a></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<p>In this section we’ll cover</p>
<ul class="simple">
<li><p>what outputs come from Spinning Up algorithm implementations,</p></li>
<li><p>what formats they’re stored in and how they’re organized,</p></li>
<li><p>where they are stored and how you can change that,</p></li>
<li><p>and how to load and run trained policies.</p></li>
</ul>
<div class="admonition-you-should-know admonition">
<p class="admonition-title">You Should Know</p>
<p>Spinning Up implementations currently have no way to resume training for partially-trained agents. If you consider this feature important, please let us know—or consider it a hacking project!</p>
</div>
<section id="algorithm-outputs">
<h2><a class="toc-backref" href="#id2">Algorithm Outputs</a><a class="headerlink" href="#algorithm-outputs" title="Permalink to this headline">¶</a></h2>
<p>Each algorithm is set up to save a training run’s hyperparameter configuration, learning progress, trained agent and value functions, and a copy of the environment if possible (to make it easy to load up the agent and environment simultaneously). The output directory contains the following:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 20%" />
<col style="width: 80%" />
</colgroup>
<tbody>
<tr class="row-odd"><td colspan="2"><p><strong>Output Directory Structure</strong></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">pyt_save/</span></code></p></td>
<td><div class="line-block">
<div class="line"><strong>PyTorch implementations only.</strong> A directory containing</div>
<div class="line">everything needed to restore the trained agent and value</div>
<div class="line">functions. (<a class="reference internal" href="#details-for-pytorch-saves-below">Details for PyTorch saves below.</a>)</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">tf1_save/</span></code></p></td>
<td><div class="line-block">
<div class="line"><strong>Tensorflow implementations only.</strong> A directory containing</div>
<div class="line">everything needed to restore the trained agent and value</div>
<div class="line">functions. (<a class="reference internal" href="#details-for-tensorflow-saves-below">Details for Tensorflow saves below.</a>)</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">config.json</span></code></p></td>
<td><div class="line-block">
<div class="line">A dict containing an as-complete-as-possible description</div>
<div class="line">of the args and kwargs you used to launch the training</div>
<div class="line">function. If you passed in something which can’t be</div>
<div class="line">serialized to JSON, it should get handled gracefully by the</div>
<div class="line">logger, and the config file will represent it with a string.</div>
<div class="line">Note: this is meant for record-keeping only. Launching an</div>
<div class="line">experiment from a config file is not currently supported.</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">progress.txt</span></code></p></td>
<td><div class="line-block">
<div class="line">A tab-separated value file containing records of the metrics</div>
<div class="line">recorded by the logger throughout training. eg, <code class="docutils literal notranslate"><span class="pre">Epoch</span></code>,</div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">AverageEpRet</span></code>, etc.</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">vars.pkl</span></code></p></td>
<td><div class="line-block">
<div class="line">A pickle file containing anything about the algorithm state</div>
<div class="line">which should get stored. Currently, all algorithms only use</div>
<div class="line">this to save a copy of the environment.</div>
</div>
</td>
</tr>
</tbody>
</table>
<div class="admonition-you-should-know admonition">
<p class="admonition-title">You Should Know</p>
<p>Sometimes environment-saving fails because the environment can’t be pickled, and <code class="docutils literal notranslate"><span class="pre">vars.pkl</span></code> is empty. This is known to be a problem for Gym Box2D environments in older versions of Gym, which can’t be saved in this manner.</p>
</div>
<div class="admonition-you-should-know admonition">
<p class="admonition-title">You Should Know</p>
<p>As of 1/30/20, the save directory structure has changed slightly. Previously, Tensorflow graphs were saved in the <code class="docutils literal notranslate"><span class="pre">simple_save/</span></code> folder; this has been replaced with <code class="docutils literal notranslate"><span class="pre">tf1_save/</span></code>.</p>
</div>
<div class="admonition-you-should-know admonition">
<p class="admonition-title">You Should Know</p>
<p>The only file in here that you should ever have to use “by hand” is the <code class="docutils literal notranslate"><span class="pre">config.json</span></code> file. Our agent testing utility will load things from the <code class="docutils literal notranslate"><span class="pre">tf1_save/</span></code> or <code class="docutils literal notranslate"><span class="pre">pyt_save/</span></code> directory, and our plotter interprets the contents of <code class="docutils literal notranslate"><span class="pre">progress.txt</span></code>, and those are the correct tools for interfacing with these outputs. But there is no tooling for <code class="docutils literal notranslate"><span class="pre">config.json</span></code>—it’s just there so that if you forget what hyperparameters you ran an experiment with, you can double-check.</p>
</div>
<section id="pytorch-save-directory-info">
<h3><a class="toc-backref" href="#id3">PyTorch Save Directory Info</a><a class="headerlink" href="#pytorch-save-directory-info" title="Permalink to this headline">¶</a></h3>
<p id="details-for-pytorch-saves-below">The <code class="docutils literal notranslate"><span class="pre">pyt_save</span></code> directory contains:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 22%" />
<col style="width: 78%" />
</colgroup>
<tbody>
<tr class="row-odd"><td colspan="2"><p><strong>Pyt_Save Directory Structure</strong></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">model.pt</span></code></p></td>
<td><div class="line-block">
<div class="line">A file created with <code class="docutils literal notranslate"><span class="pre">torch.save</span></code>, essentially just a</div>
<div class="line">pickled PyTorch <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code>. Loading it will restore</div>
<div class="line">a trained agent as an ActorCritic object with an <code class="docutils literal notranslate"><span class="pre">act</span></code></div>
<div class="line">method.</div>
</div>
</td>
</tr>
</tbody>
</table>
</section>
<section id="tensorflow-save-directory-info">
<h3><a class="toc-backref" href="#id4">Tensorflow Save Directory Info</a><a class="headerlink" href="#tensorflow-save-directory-info" title="Permalink to this headline">¶</a></h3>
<p id="details-for-tensorflow-saves-below">The <code class="docutils literal notranslate"><span class="pre">tf1_save</span></code> directory contains:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 22%" />
<col style="width: 78%" />
</colgroup>
<tbody>
<tr class="row-odd"><td colspan="2"><p><strong>TF1_Save Directory Structure</strong></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">variables/</span></code></p></td>
<td><div class="line-block">
<div class="line">A directory containing outputs from the Tensorflow Saver.</div>
<div class="line">See documentation for <a class="reference external" href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/README.md">Tensorflow SavedModel</a>.</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">model_info.pkl</span></code></p></td>
<td><div class="line-block">
<div class="line">A dict containing information (map from key to tensor name)</div>
<div class="line">which helps us unpack the saved model after loading.</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">saved_model.pb</span></code></p></td>
<td><div class="line-block">
<div class="line">A protocol buffer, needed for a <a class="reference external" href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/README.md">Tensorflow SavedModel</a>.</div>
</div>
</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="save-directory-location">
<h2><a class="toc-backref" href="#id5">Save Directory Location</a><a class="headerlink" href="#save-directory-location" title="Permalink to this headline">¶</a></h2>
<p>Experiment results will, by default, be saved in the same directory as the Spinning Up package, in a folder called <code class="docutils literal notranslate"><span class="pre">data</span></code>:</p>
<pre class="literal-block">spinningup/
    <strong>data/</strong>
        ...
    docs/
        ...
    spinup/
        ...
    LICENSE
    setup.py</pre>
<p>You can change the default results directory by modifying <code class="docutils literal notranslate"><span class="pre">DEFAULT_DATA_DIR</span></code> in <code class="docutils literal notranslate"><span class="pre">spinup/user_config.py</span></code>.</p>
</section>
<section id="loading-and-running-trained-policies">
<h2><a class="toc-backref" href="#id6">Loading and Running Trained Policies</a><a class="headerlink" href="#loading-and-running-trained-policies" title="Permalink to this headline">¶</a></h2>
<section id="if-environment-saves-successfully">
<h3><a class="toc-backref" href="#id7">If Environment Saves Successfully</a><a class="headerlink" href="#if-environment-saves-successfully" title="Permalink to this headline">¶</a></h3>
<p>For cases where the environment is successfully saved alongside the agent, it’s a cinch to watch the trained agent act in the environment using:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">spinup</span><span class="o">.</span><span class="n">run</span> <span class="n">test_policy</span> <span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">output_directory</span>
</pre></div>
</div>
<p>There are a few flags for options:</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-l">
<span id="cmdoption-len"></span><span id="cmdoption-arg-default"></span><span class="sig-name descname"><span class="pre">-l</span></span><span class="sig-prename descclassname"> <span class="pre">L</span></span><span class="sig-prename descclassname"><span class="pre">,</span> </span><span class="sig-name descname"><span class="pre">--len</span></span><span class="sig-prename descclassname"><span class="pre">=L</span></span><span class="sig-prename descclassname"><span class="pre">,</span> </span><span class="sig-name descname"><span class="pre">default</span></span><span class="sig-prename descclassname"><span class="pre">=0</span></span><a class="headerlink" href="#cmdoption-l" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em>. Maximum length of test episode / trajectory / rollout. The default of 0 means no maximum episode length—episodes only end when the agent has reached a terminal state in the environment. (Note: setting L=0 will not prevent Gym envs wrapped by TimeLimit wrappers from ending when they reach their pre-set maximum episode length.)</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-n">
<span id="cmdoption-episodes"></span><span id="cmdoption-arg-0"></span><span class="sig-name descname"><span class="pre">-n</span></span><span class="sig-prename descclassname"> <span class="pre">N</span></span><span class="sig-prename descclassname"><span class="pre">,</span> </span><span class="sig-name descname"><span class="pre">--episodes</span></span><span class="sig-prename descclassname"><span class="pre">=N</span></span><span class="sig-prename descclassname"><span class="pre">,</span> </span><span class="sig-name descname"><span class="pre">default</span></span><span class="sig-prename descclassname"><span class="pre">=100</span></span><a class="headerlink" href="#cmdoption-n" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em>. Number of test episodes to run the agent for.</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-nr">
<span id="cmdoption-norender"></span><span class="sig-name descname"><span class="pre">-nr</span></span><span class="sig-prename descclassname"></span><span class="sig-prename descclassname"><span class="pre">,</span> </span><span class="sig-name descname"><span class="pre">--norender</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-nr" title="Permalink to this definition">¶</a></dt>
<dd><p>Do not render the test episodes to the screen. In this case, <code class="docutils literal notranslate"><span class="pre">test_policy</span></code> will only print the episode returns and lengths. (Use case: the renderer slows down the testing process, and you just want to get a fast sense of how the agent is performing, so you don’t particularly care to watch it.)</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-i">
<span id="cmdoption-itr"></span><span id="cmdoption-arg-1"></span><span class="sig-name descname"><span class="pre">-i</span></span><span class="sig-prename descclassname"> <span class="pre">I</span></span><span class="sig-prename descclassname"><span class="pre">,</span> </span><span class="sig-name descname"><span class="pre">--itr</span></span><span class="sig-prename descclassname"><span class="pre">=I</span></span><span class="sig-prename descclassname"><span class="pre">,</span> </span><span class="sig-name descname"><span class="pre">default</span></span><span class="sig-prename descclassname"><span class="pre">=-1</span></span><a class="headerlink" href="#cmdoption-i" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em>. This is an option for a special case which is not supported by algorithms in this package as-shipped, but which they are easily modified to do. Use case: Sometimes it’s nice to watch trained agents from many different points in training (eg watch at iteration 50, 100, 150, etc.). The logger can do this—save snapshots of the agent from those different points, so they can be run and watched later. In this case, you use this flag to specify which iteration to run. But again: spinup algorithms by default only save snapshots of the most recent agent, overwriting the old snapshots.</p>
<p>The default value of this flag means “use the latest snapshot.”</p>
<p>To modify an algo so it does produce multiple snapshots, find the following line (which is present in all of the algorithms):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">logger</span><span class="o">.</span><span class="n">save_state</span><span class="p">({</span><span class="s1">&#39;env&#39;</span><span class="p">:</span> <span class="n">env</span><span class="p">},</span> <span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
<p>and tweak it to</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">logger</span><span class="o">.</span><span class="n">save_state</span><span class="p">({</span><span class="s1">&#39;env&#39;</span><span class="p">:</span> <span class="n">env</span><span class="p">},</span> <span class="n">epoch</span><span class="p">)</span>
</pre></div>
</div>
<p>Make sure to then also set <code class="docutils literal notranslate"><span class="pre">save_freq</span></code> to something reasonable (because if it defaults to 1, for instance, you’ll flood your output directory with one <code class="docutils literal notranslate"><span class="pre">save</span></code> folder for each snapshot—which adds up fast).</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-d">
<span id="cmdoption-deterministic"></span><span class="sig-name descname"><span class="pre">-d</span></span><span class="sig-prename descclassname"></span><span class="sig-prename descclassname"><span class="pre">,</span> </span><span class="sig-name descname"><span class="pre">--deterministic</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-d" title="Permalink to this definition">¶</a></dt>
<dd><p>Another special case, which is only used for SAC. The Spinning Up SAC implementation trains a stochastic policy, but is evaluated using the deterministic <em>mean</em> of the action distribution. <code class="docutils literal notranslate"><span class="pre">test_policy</span></code> will default to using the stochastic policy trained by SAC, but you should set the deterministic flag to watch the deterministic mean policy (the correct evaluation policy for SAC). This flag is not used for any other algorithms.</p>
</dd></dl>

</section>
<section id="environment-not-found-error">
<h3><a class="toc-backref" href="#id8">Environment Not Found Error</a><a class="headerlink" href="#environment-not-found-error" title="Permalink to this headline">¶</a></h3>
<p>If the environment wasn’t saved successfully, you can expect <code class="docutils literal notranslate"><span class="pre">test_policy.py</span></code> to crash with something that looks like</p>
<pre class="literal-block">Traceback (most recent call last):
  File &quot;spinup/utils/test_policy.py&quot;, line 153, in &lt;module&gt;
    run_policy(env, get_action, args.len, args.episodes, not(args.norender))
  File &quot;spinup/utils/test_policy.py&quot;, line 114, in run_policy
    &quot;and we can't run the agent in it. :( nn Check out the readthedocs &quot; +
AssertionError: Environment not found!

 It looks like the environment wasn't saved, and we can't run the agent in it. :(

 Check out the readthedocs page on Experiment Outputs for how to handle this situation.</pre>
<p>In this case, watching your agent perform is slightly more of a pain but not impossible, as long as you can recreate your environment easily. Try the following in IPython:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">spinup.utils.test_policy</span> <span class="kn">import</span> <span class="n">load_policy_and_env</span><span class="p">,</span> <span class="n">run_policy</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">your_env</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span><span class="p">,</span> <span class="n">get_action</span> <span class="o">=</span> <span class="n">load_policy_and_env</span><span class="p">(</span><span class="s1">&#39;/path/to/output_directory&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">env</span> <span class="o">=</span> <span class="n">your_env</span><span class="o">.</span><span class="n">make</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">run_policy</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">get_action</span><span class="p">)</span>
<span class="go">Logging data to /tmp/experiments/1536150702/progress.txt</span>
<span class="go">Episode 0    EpRet -163.830      EpLen 93</span>
<span class="go">Episode 1    EpRet -346.164      EpLen 99</span>
<span class="gp">...</span>
</pre></div>
</div>
</section>
<section id="using-trained-value-functions">
<h3><a class="toc-backref" href="#id9">Using Trained Value Functions</a><a class="headerlink" href="#using-trained-value-functions" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">test_policy.py</span></code> tool doesn’t help you look at trained value functions, and if you want to use those, you will have to do some digging by hand. For the PyTorch case, load the saved model file with <code class="docutils literal notranslate"><span class="pre">torch.load</span></code> and check the documentation for each algorithm to see what modules the ActorCritic object has. For the Tensorflow case, load the saved computation graph with the <a class="reference external" href="../utils/logger.html#spinup.utils.logx.restore_tf_graph">restore_tf_graph</a> function, and check the documentation for each algorithm to see what functions were saved.</p>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../index.html">multi-agent-market-rl</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../MultiAgentMarketRL.html">Multi-Agent-Market-RL</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2021, Benjamin Suter.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.1.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../../../../_sources/submodules/spinningup-rl-tutorial/docs/user/saving_and_loading.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>